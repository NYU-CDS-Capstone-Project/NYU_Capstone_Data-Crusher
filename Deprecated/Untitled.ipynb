{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(data_directory + 'qaData.csv', parse_dates=['Date'])\n",
    "orig_data['EarningTag2'] = orig_data['EarningTag2'].str.strip()\n",
    "\n",
    "#Add Year and Month, Quarter from Data\n",
    "orig_data['Year'] = orig_data['Date'].dt.year\n",
    "orig_data['Month'] = orig_data['Date'].dt.month\n",
    "orig_data['Quarter'] = orig_data['Month'].apply(lambda x: 1 if x < 4 else 2 if x < 7 else 3 if x < 9 else 4)\n",
    "orig_data['Company'] = orig_data['Company'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['EventType'] = orig_data['EventType'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['Participants'] = orig_data['Participants'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['AnalystName'] = orig_data['AnalystName'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['AnalystCompany'] = orig_data['AnalystCompany'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['Tag'] = orig_data['EarningTag2'].str.title().str.replace(\" \", \"\")\n",
    "\n",
    "orig_data = orig_data.loc[~orig_data['AnalystName'].isna()].copy()\n",
    "\n",
    "tag_cols = orig_data['Tag'].unique().tolist()\n",
    "\n",
    "#Index Data\n",
    "groups = []\n",
    "for i, (name, group) in enumerate(orig_data.groupby(['Company', 'Participants', 'Month', 'Year', 'Quarter', 'EventType', 'Date'])):\n",
    "    g2 = group.copy()\n",
    "    g2['EventNumber'] = i\n",
    "    groups.append(g2)\n",
    "    \n",
    "indexed_data = pd.concat(groups)\n",
    "\n",
    "analyst_data = pd.read_csv(data_directory+\"analystTopic.csv\")\n",
    "a_topic_cols = analyst_data.drop(['AnalystName', 'EventNumber', 'a_tMax'], axis=1).columns.tolist()\n",
    "topic_cols = a_topic_cols.copy()\n",
    "indexed_data = indexed_data.merge(analyst_data[['AnalystName', 'EventNumber', 'a_tMax']], on=['AnalystName','EventNumber'])\n",
    "\n",
    "tag_data = pd.read_csv(data_directory+\"tagTopic.csv\")\n",
    "t_topic_cols = tag_data.drop(['Tag', 'EventNumber', 't_tMax'], axis=1).columns.tolist()\n",
    "topic_cols += t_topic_cols.copy()\n",
    "indexed_data = indexed_data.merge(tag_data[['Tag', 'EventNumber', 't_tMax']], on=['Tag','EventNumber'])\n",
    "\n",
    "cols_save = ['EventNumber','Company', 'Month', 'Year', 'Quarter', 'EventType']\n",
    "\n",
    "pivot_data = pd.pivot_table(indexed_data, index=cols_save, columns=['a_tMax','t_tMax'], aggfunc='size', fill_value=0).reset_index()\n",
    "pivot_data.columns = ['__'.join(col).rstrip('__') for col in pivot_data.columns.values]\n",
    "melt_data = pd.melt(pivot_data, id_vars=cols_save, var_name=['a_tMax__t_tMax'], value_name='NumQ')\n",
    "melt_data[['a_tMax', 't_tMax']] = melt_data['a_tMax__t_tMax'].str.split(\"__\", expand=True)\n",
    "melt_data['NumQ'] = melt_data['NumQ'].astype(bool).astype(int)\n",
    "melt_data = pd.concat([melt_data,\n",
    "                          pd.get_dummies(melt_data[['a_tMax', 't_tMax', 'Company', 'EventType']])], axis=1).reset_index(drop=True)\n",
    "\n",
    "features_data = melt_data.drop(['Company', 'EventType', 'a_tMax', 't_tMax', 'a_tMax__t_tMax'], axis=1).copy()\n",
    "train, test = features_data.loc[~features_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True), \\\n",
    "                features_data.loc[features_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = train.drop(['NumQ','EventNumber'], axis=1).values, train['NumQ'].values\n",
    "X_test, y_test = test.drop(['NumQ', 'EventNumber'], axis=1).values, test['NumQ'].values\n",
    "\n",
    "cols_list = train.drop(['NumQ','EventNumber'], axis=1).columns.values\n",
    "\n",
    "print(\"Data Size: {}\".format(features_data.shape))\n",
    "\n",
    "estimator = RandomForestClassifier(warm_start=True, n_estimators=1000).fit(X_train, y_train)\n",
    "preds = estimator.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, preds))\n",
    "print(accuracy_score(y_test, preds.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(data_directory + 'qaData.csv', parse_dates=['Date'])\n",
    "orig_data['EarningTag2'] = orig_data['EarningTag2'].str.strip()\n",
    "\n",
    "#Add Year and Month, Quarter from Data\n",
    "orig_data['Year'] = orig_data['Date'].dt.year\n",
    "orig_data['Month'] = orig_data['Date'].dt.month\n",
    "orig_data['Quarter'] = orig_data['Month'].apply(lambda x: 1 if x < 4 else 2 if x < 7 else 3 if x < 9 else 4)\n",
    "orig_data['Company'] = orig_data['Company'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['EventType'] = orig_data['EventType'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['Participants'] = orig_data['Participants'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['AnalystName'] = orig_data['AnalystName'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['AnalystCompany'] = orig_data['AnalystCompany'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['Tag'] = orig_data['EarningTag2'].str.title().str.replace(\" \", \"\")\n",
    "\n",
    "orig_data = orig_data.loc[~orig_data['AnalystName'].isna()].copy()\n",
    "\n",
    "tag_cols = orig_data['Tag'].unique().tolist()\n",
    "\n",
    "#Index Data\n",
    "groups = []\n",
    "for i, (name, group) in enumerate(orig_data.groupby(['Company', 'Participants', 'Month', 'Year', 'Quarter', 'EventType', 'Date'])):\n",
    "    g2 = group.copy()\n",
    "    g2['EventNumber'] = i\n",
    "    groups.append(g2)\n",
    "    \n",
    "indexed_data = pd.concat(groups)\n",
    "\n",
    "analyst_data = pd.read_csv(data_directory+\"analystTopic.csv\")\n",
    "a_topic_cols = analyst_data.drop(['AnalystName', 'EventNumber'], axis=1).columns.tolist()\n",
    "topic_cols = a_topic_cols.copy()\n",
    "indexed_data = indexed_data.merge(analyst_data, on=['AnalystName','EventNumber'])\n",
    "\n",
    "tag_data = pd.read_csv(data_directory+\"tagTopic.csv\")\n",
    "t_topic_cols = tag_data.drop(['Tag', 'EventNumber'], axis=1).columns.tolist()\n",
    "topic_cols += t_topic_cols.copy()\n",
    "indexed_data = indexed_data.merge(tag_data, on=['Tag','EventNumber'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cols_save = ['EventNumber','Company', 'Month', 'Year', 'Quarter', 'EventType', 'Date']\n",
    "\n",
    "pivot_data = pd.pivot_table(indexed_data, index=cols_save, columns=['a_tMax', 'Tag'], aggfunc='size', fill_value=0).reset_index()\n",
    "pivot_data.columns = ['__'.join(col).rstrip('__') for col in pivot_data.columns.values]\n",
    "melt_data = pd.melt(pivot_data, id_vars=cols_save, var_name=['a_tMax__Tag'], value_name='NumQ')\n",
    "melt_data[['a_tMax', 'Tag']] = melt_data['a_tMax__Tag'].str.split(\"__\", expand=True)\n",
    "melt_data['NumQ'] = melt_data['NumQ'].astype(bool).astype(int)\n",
    "melt_data = pd.concat([melt_data, \n",
    "                        pd.get_dummies(melt_data[['Company', 'EventType', 'Tag']])], axis=1).reset_index(drop=True)\n",
    "\n",
    "#for i in ['a_tMax', 'Company', 'Quarter']:\n",
    "    \n",
    "#    hist_data = historicVarPct(melt_data, i, 'Tag')\n",
    "#    melt_data = pd.merge(melt_data, hist_data, on=[i, 'Company', 'Date'])\n",
    "\n",
    "\n",
    "features_data = melt_data.drop(['Company', 'Tag', 'EventType', 'Date' , 'Year', 'a_tMax', 'a_tMax__Tag'], axis=1).copy()\n",
    "features_data = features_data.reset_index(drop=True)\n",
    "features_data['NumQ'] = features_data['NumQ'].astype(bool).astype(int)\n",
    "\n",
    "train, test = features_data.loc[~features_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True), \\\n",
    "                features_data.loc[features_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = train.drop(['NumQ','EventNumber'], axis=1).values, train['NumQ'].values\n",
    "X_test, y_test = test.drop(['NumQ', 'EventNumber'], axis=1).values, test['NumQ'].values\n",
    "\n",
    "cols_list = train.drop(['NumQ','EventNumber'], axis=1).columns.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
